{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import math\n",
    "import h5py\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Device: NVIDIA GeForce RTX 4060\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA is available. Device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumTransformer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, num_layers, dim_feedforward, dropout, seq_length, n_grid, device):\n",
    "        super(QuantumTransformer, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Linear(3, d_model)  # (Re(Ψ), Im(Ψ), V) → d_model\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.positional_encoding = self.create_positional_encoding(seq_length * n_grid, d_model).to(device)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=num_heads, dim_feedforward=dim_feedforward, dropout=dropout\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Output layer (maps d_model back to (Re(Ψ), Im(Ψ)))\n",
    "        self.output_layer = nn.Linear(d_model, 2)\n",
    "\n",
    "    def create_positional_encoding(self, full_seq_length, d_model):\n",
    "        \"\"\"\n",
    "        Generate a positional encoding tensor of shape (1, full_seq_length, d_model).\n",
    "        \"\"\"\n",
    "        pos_encoding = torch.zeros(full_seq_length, d_model)\n",
    "        position = torch.arange(0, full_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pos_encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        pos_encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        return pos_encoding.unsqueeze(0)  # Shape: (1, full_seq_length, d_model)\n",
    "\n",
    "    def forward(self, psi_real, psi_imag, potential):\n",
    "        # Stack input features along last dimension\n",
    "        x = torch.stack((psi_real, psi_imag, potential), dim=-1)  # Shape: (batch, seq_length, n_grid, 3)\n",
    "        \n",
    "        # Flatten the n_grid dimension into the sequence dimension\n",
    "        batch_size, seq_length, n_grid, _ = x.shape\n",
    "        x = x.view(batch_size, seq_length * n_grid, 3)\n",
    "\n",
    "        # Apply embedding\n",
    "        x = self.embedding(x)  # Shape: (batch, seq_length * n_grid, d_model)\n",
    "        \n",
    "        # Add positional encoding (matching seq_length)\n",
    "        x = x + self.positional_encoding[:, :x.shape[1], :].to(x.device)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # Apply output layer\n",
    "        x = self.output_layer(x)  # Shape: (batch, seq_length * n_grid, 2)\n",
    "\n",
    "        # Reshape back to (batch, seq_length, n_grid, 2)\n",
    "        x = x.view(batch_size, seq_length, n_grid, 2)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumWaveDataset(Dataset):\n",
    "    def __init__(self, h5_file):\n",
    "        \"\"\"\n",
    "        Custom PyTorch Dataset for quantum wavefunction propagation.\n",
    "        - h5_file: Path to the .h5 file containing dataset_X and dataset_y.\n",
    "        \"\"\"\n",
    "        with h5py.File(h5_file, \"r\") as f:\n",
    "            self.X = torch.tensor(f[\"dataset_X\"][:], dtype=torch.float32)  # Shape (num_trajectories, sequence_length, n_grid * 3)\n",
    "            self.y = torch.tensor(f[\"dataset_y\"][:], dtype=torch.float32)  # Shape (num_trajectories, sequence_length, n_grid * 2)\n",
    "\n",
    "        # Extract num_trajectories, sequence_length, and n_grid from the shape\n",
    "        self.num_trajectories, self.sequence_length, n_grid_3 = self.X.shape\n",
    "        self.n_grid = n_grid_3 // 3  # Since last dimension is n_grid * 3\n",
    "\n",
    "        # Reshape to (num_trajectories, sequence_length, n_grid, features)\n",
    "        self.X = self.X.view(self.num_trajectories, self.sequence_length, self.n_grid, 3)\n",
    "        self.y = self.y.view(self.num_trajectories, self.sequence_length, self.n_grid, 2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_trajectories\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]  # Each sample is (sequence_length, n_grid, features)\n",
    "\n",
    "# Load dataset\n",
    "h5_path = \"./DataNew/ngrid64_19932025.h5\"  # Change this to your actual path\n",
    "dataset = QuantumWaveDataset(h5_path)\n",
    "\n",
    "# Create DataLoader for training\n",
    "batch_size = 10\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = QuantumTransformer(seq_length=dataset.sequence_length, d_model=128, num_heads=8, num_layers=6, dim_feedforward=512, n_grid=64, dropout=0.1, device=device).to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.191330\n",
      "Epoch 2/50, Loss: 0.665365\n",
      "Epoch 3/50, Loss: 0.379064\n",
      "Epoch 4/50, Loss: 0.293006\n",
      "Epoch 5/50, Loss: 0.312087\n",
      "Epoch 6/50, Loss: 0.341239\n",
      "Epoch 7/50, Loss: 0.336964\n",
      "Epoch 8/50, Loss: 0.304093\n",
      "Epoch 9/50, Loss: 0.257478\n",
      "Epoch 10/50, Loss: 0.210535\n",
      "Epoch 11/50, Loss: 0.175002\n",
      "Epoch 12/50, Loss: 0.154825\n",
      "Epoch 13/50, Loss: 0.150757\n",
      "Epoch 14/50, Loss: 0.156608\n",
      "Epoch 15/50, Loss: 0.166590\n",
      "Epoch 16/50, Loss: 0.174978\n",
      "Epoch 17/50, Loss: 0.177761\n",
      "Epoch 18/50, Loss: 0.173901\n",
      "Epoch 19/50, Loss: 0.164949\n",
      "Epoch 20/50, Loss: 0.153228\n",
      "Epoch 21/50, Loss: 0.142327\n",
      "Epoch 22/50, Loss: 0.134500\n",
      "Epoch 23/50, Loss: 0.130680\n",
      "Epoch 24/50, Loss: 0.131102\n",
      "Epoch 25/50, Loss: 0.133666\n",
      "Epoch 26/50, Loss: 0.137510\n",
      "Epoch 27/50, Loss: 0.140553\n",
      "Epoch 28/50, Loss: 0.140740\n",
      "Epoch 29/50, Loss: 0.139102\n",
      "Epoch 30/50, Loss: 0.135306\n",
      "Epoch 31/50, Loss: 0.131263\n",
      "Epoch 32/50, Loss: 0.128352\n",
      "Epoch 33/50, Loss: 0.125893\n",
      "Epoch 34/50, Loss: 0.125120\n",
      "Epoch 35/50, Loss: 0.125563\n",
      "Epoch 36/50, Loss: 0.126328\n",
      "Epoch 37/50, Loss: 0.127818\n",
      "Epoch 38/50, Loss: 0.128022\n",
      "Epoch 39/50, Loss: 0.127880\n",
      "Epoch 40/50, Loss: 0.127461\n",
      "Epoch 41/50, Loss: 0.125674\n",
      "Epoch 42/50, Loss: 0.124410\n",
      "Epoch 43/50, Loss: 0.123014\n",
      "Epoch 44/50, Loss: 0.122526\n",
      "Epoch 45/50, Loss: 0.122490\n",
      "Epoch 46/50, Loss: 0.122471\n",
      "Epoch 47/50, Loss: 0.123166\n",
      "Epoch 48/50, Loss: 0.123253\n",
      "Epoch 49/50, Loss: 0.123070\n",
      "Epoch 50/50, Loss: 0.123118\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Split inputs into components\n",
    "        psi_real = X[..., 0]  # (batch_size, seq_length, n_grid)\n",
    "        psi_imag = X[..., 1]  # (batch_size, seq_length, n_grid)\n",
    "        potential = X[..., 2] # (batch_size, seq_length, n_grid)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(psi_real, psi_imag, potential)  # Output shape: (batch_size, seq_length, n_grid, 2)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def propagate_wavefunction(model, initial_psi_real, initial_psi_imag, potential, N, device):\n",
    "    \"\"\"\n",
    "    Propagates the wavefunction using the trained Transformer model for N time steps.\n",
    "\n",
    "    Parameters:\n",
    "    - model: Trained Transformer model.\n",
    "    - initial_psi_real: Initial real part of the wavefunction, shape (1, n_grid).\n",
    "    - initial_psi_imag: Initial imaginary part of the wavefunction, shape (1, n_grid).\n",
    "    - potential: Potential energy function, shape (N, n_grid).\n",
    "    - N: Number of time steps to propagate.\n",
    "    - device: 'cuda' or 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "    - propagated_wavefunction: List of predicted wavefunctions [(Re, Im)] for each time step.\n",
    "    \"\"\"\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    propagated_wavefunction = []\n",
    "    \n",
    "    # Move to device\n",
    "    psi_real = initial_psi_real.to(device)\n",
    "    psi_imag = initial_psi_imag.to(device)\n",
    "    potential = potential.to(device)\n",
    "\n",
    "    for t in range(N):\n",
    "        # Extract potential at current time step\n",
    "        V_t = potential[t].unsqueeze(0)  # Shape: (1, n_grid)\n",
    "        # Run through the Transformer model\n",
    "        with torch.no_grad():\n",
    "            psi_real, psi_imag = model(psi_real, psi_imag, V_t)\n",
    "\n",
    "        propagated_wavefunction.append((psi_real.cpu().numpy(), psi_imag.cpu().numpy()))\n",
    "\n",
    "    return propagated_wavefunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "def animate_propagation(propagated_wave, dvr_wave, n_grid):\n",
    "    \"\"\"\n",
    "    Animates the wavefunction propagation from the Transformer model compared to DVR.\n",
    "\n",
    "    Parameters:\n",
    "    - propagated_wave: List of (Re, Im) wavefunction tuples from the Transformer.\n",
    "    - dvr_wave: Ground truth wavefunction from the dataset [(Re, Im)].\n",
    "    - n_grid: Number of spatial grid points.\n",
    "    \"\"\"\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "    x = np.linspace(0, 1, n_grid)  # Adjust the spatial domain accordingly\n",
    "    line1, = ax[0].plot([], [], 'b-', label=\"Transformer Re(Ψ)\")\n",
    "    line2, = ax[0].plot([], [], 'r-', label=\"DVR Re(Ψ)\")\n",
    "    ax[0].set_ylim(-1, 1)\n",
    "    ax[0].set_xlim(x[0], x[-1])\n",
    "    ax[0].set_title(\"Real Part of Wavefunction\")\n",
    "    ax[0].legend()\n",
    "\n",
    "    line3, = ax[1].plot([], [], 'b-', label=\"Transformer Im(Ψ)\")\n",
    "    line4, = ax[1].plot([], [], 'r-', label=\"DVR Im(Ψ)\")\n",
    "    ax[1].set_ylim(-1, 1)\n",
    "    ax[1].set_xlim(x[0], x[-1])\n",
    "    ax[1].set_title(\"Imaginary Part of Wavefunction\")\n",
    "    ax[1].legend()\n",
    "\n",
    "    def init():\n",
    "        line1.set_data([], [])\n",
    "        line2.set_data([], [])\n",
    "        line3.set_data([], [])\n",
    "        line4.set_data([], [])\n",
    "        return line1, line2, line3, line4\n",
    "\n",
    "    def update(frame):\n",
    "        psi_real_trans, psi_imag_trans = propagated_wave[frame]\n",
    "        psi_real_dvr, psi_imag_dvr = dvr_wave[frame]\n",
    "\n",
    "        line1.set_data(x, psi_real_trans)\n",
    "        line2.set_data(x, psi_real_dvr)\n",
    "        line3.set_data(x, psi_imag_trans)\n",
    "        line4.set_data(x, psi_imag_dvr)\n",
    "        return line1, line2, line3, line4\n",
    "\n",
    "    ani = animation.FuncAnimation(fig, update, frames=len(propagated_wave), init_func=init, blit=True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from .h5 file\n",
    "dataset_path = h5_path  # Replace with your actual file path\n",
    "\n",
    "with h5py.File(dataset_path, \"r\") as f:\n",
    "    dataset_X = torch.tensor(f[\"dataset_X\"][:], dtype=torch.float32)\n",
    "    dataset_Y = torch.tensor(f[\"dataset_y\"][:], dtype=torch.float32)\n",
    "\n",
    "# Move dataset to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dataset_X, dataset_Y = dataset_X.to(device), dataset_Y.to(device)\n",
    "\n",
    "# Get dataset dimensions\n",
    "num_trajectories, sequence_length, total_features = dataset_X.shape\n",
    "n_grid = total_features // 3  # Since input has (Re(Ψ), Im(Ψ), V)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a trajectory (e.g., the first one)\n",
    "trajectory_idx = 0\n",
    "\n",
    "# Extract initial real and imaginary parts of wavefunction (t=0)\n",
    "initial_psi_real = dataset_X[trajectory_idx, 0, :n_grid].unsqueeze(0)  # Shape: (1, n_grid)\n",
    "initial_psi_imag = dataset_X[trajectory_idx, 0, n_grid:2*n_grid].unsqueeze(0)\n",
    "\n",
    "# Extract the potential for all timesteps\n",
    "potential = dataset_X[trajectory_idx, :, 2*n_grid:]  # Shape: (sequence_length, n_grid)\n",
    "\n",
    "# Extract DVR ground truth wavefunction for comparison\n",
    "dvr_wave = [(dataset_Y[trajectory_idx, i, :n_grid], dataset_Y[trajectory_idx, i, n_grid:]) for i in range(sequence_length)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "stack expects each tensor to be equal size, but got [1, 1, 1, 64] at entry 0 and [1, 1, 100, 64] at entry 2",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m potential = potential.unsqueeze(\u001b[32m0\u001b[39m)  \u001b[38;5;66;03m# Shape: (1, sequence_length, n_grid)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Call the function again\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m propagated_wave = \u001b[43mpropagate_wavefunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_psi_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_psi_imag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpotential\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mpropagate_wavefunction\u001b[39m\u001b[34m(model, initial_psi_real, initial_psi_imag, potential, N, device)\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Run through the Transformer model\u001b[39;00m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m         psi_real, psi_imag = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi_imag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     propagated_wavefunction.append((psi_real.cpu().numpy(), psi_imag.cpu().numpy()))\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m propagated_wavefunction\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mQuantumTransformer.forward\u001b[39m\u001b[34m(self, psi_real, psi_imag, potential)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, psi_real, psi_imag, potential):\n\u001b[32m     33\u001b[39m     \u001b[38;5;66;03m# Stack input features along last dimension\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m     x = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi_imag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpotential\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Shape: (batch, seq_length, n_grid, 3)\u001b[39;00m\n\u001b[32m     36\u001b[39m     \u001b[38;5;66;03m# Flatten the n_grid dimension into the sequence dimension\u001b[39;00m\n\u001b[32m     37\u001b[39m     batch_size, seq_length, n_grid, _ = x.shape\n",
      "\u001b[31mRuntimeError\u001b[39m: stack expects each tensor to be equal size, but got [1, 1, 1, 64] at entry 0 and [1, 1, 100, 64] at entry 2"
     ]
    }
   ],
   "source": [
    "N = sequence_length  # Number of time steps to propagate\n",
    "\n",
    "# Ensure the tensors have correct shape: (batch_size, seq_length, n_grid)\n",
    "initial_psi_real = initial_psi_real.unsqueeze(1)  # Shape: (1, 1, n_grid)\n",
    "initial_psi_imag = initial_psi_imag.unsqueeze(1)  # Shape: (1, 1, n_grid)\n",
    "potential = potential.unsqueeze(0)  # Shape: (1, sequence_length, n_grid)\n",
    "\n",
    "# Call the function again\n",
    "propagated_wave = propagate_wavefunction(model, initial_psi_real, initial_psi_imag, potential, N, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial psi_real shape: torch.Size([1, 1, 64])\n",
      "Initial psi_imag shape: torch.Size([1, 1, 64])\n",
      "Potential shape: torch.Size([1, 100, 64])\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial psi_real shape:\", initial_psi_real.shape)  # Should be (1, 1, n_grid)\n",
    "print(\"Initial psi_imag shape:\", initial_psi_imag.shape)  # Should be (1, 1, n_grid)\n",
    "print(\"Potential shape:\", potential.shape)  # Should be (sequence_length, n_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m initial_psi_real, initial_psi_imag, potential = initial_psi_real.to(device), initial_psi_imag.to(device), potential.to(device)\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Propagate wavefunction\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m propagated_wave = \u001b[43mpropagate_wavefunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_psi_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_psi_imag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpotential\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Animate the propagation\u001b[39;00m\n\u001b[32m     10\u001b[39m animate_propagation(propagated_wave, dvr_wave, n_grid)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mpropagate_wavefunction\u001b[39m\u001b[34m(model, initial_psi_real, initial_psi_imag, potential, N, device)\u001b[39m\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# Run through the Transformer model\u001b[39;00m\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m         psi_real, psi_imag = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpsi_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi_imag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     propagated_wavefunction.append((psi_real.cpu().numpy(), psi_imag.cpu().numpy()))\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m propagated_wavefunction\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mQuantumTransformer.forward\u001b[39m\u001b[34m(self, psi_real, psi_imag, potential)\u001b[39m\n\u001b[32m     34\u001b[39m x = torch.stack((psi_real, psi_imag, potential), dim=-\u001b[32m1\u001b[39m)  \u001b[38;5;66;03m# Shape: (batch, seq_length, n_grid, 3)\u001b[39;00m\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Flatten the n_grid dimension into the sequence dimension\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m batch_size, seq_length, n_grid, _ = x.shape\n\u001b[32m     38\u001b[39m x = x.view(batch_size, seq_length * n_grid, \u001b[32m3\u001b[39m)\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Apply embedding\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 4, got 3)"
     ]
    }
   ],
   "source": [
    "N = sequence_length  # Number of time steps to propagate\n",
    "\n",
    "# Ensure tensors are on the correct device\n",
    "initial_psi_real, initial_psi_imag, potential = initial_psi_real.to(device), initial_psi_imag.to(device), potential.to(device)\n",
    "\n",
    "# Propagate wavefunction\n",
    "propagated_wave = propagate_wavefunction(model, initial_psi_real, initial_psi_imag, potential, N, device)\n",
    "\n",
    "# Animate the propagation\n",
    "animate_propagation(propagated_wave, dvr_wave, n_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=1000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.pe = pe.unsqueeze(0)  # Shape: (1, max_len, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.shape[1], :].to(x.device)\n",
    "\n",
    "class QuantumTransformer(nn.Module):\n",
    "    def __init__(self, n_grid, d_model=128, num_layers=4, num_heads=8, dim_feedforward=256, dropout=0.1):\n",
    "        super(QuantumTransformer, self).__init__()\n",
    "        self.n_grid = n_grid\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        # Linear projection of inputs\n",
    "        self.input_proj = nn.Linear(3, d_model)  # (psi_real, psi_imag, V) -> d_model\n",
    "        self.output_proj = nn.Linear(d_model, 2) # d_model -> (psi_real, psi_imag)\n",
    "        \n",
    "        # Positional encoding\n",
    "        self.positional_encoding = PositionalEncoding(d_model)\n",
    "        \n",
    "        # Transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, num_heads, dim_feedforward, dropout, batch_first=True)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        \n",
    "    def forward(self, psi_real, psi_imag, potential, mask=None):\n",
    "        batch_size, seq_length, n_grid = psi_real.shape\n",
    "        \n",
    "        # Stack inputs along last dimension: (batch, seq_length, n_grid, 3)\n",
    "        x = torch.stack((psi_real, psi_imag, potential), dim=-1)\n",
    "        x = x.view(batch_size, seq_length * n_grid, 3)  # Flatten spatial dim\n",
    "        \n",
    "        # Apply input projection and positional encoding\n",
    "        x = self.input_proj(x)\n",
    "        x = self.positional_encoding(x)\n",
    "        \n",
    "        # Transformer encoder forward pass\n",
    "        x = self.transformer_encoder(x, mask)\n",
    "        \n",
    "        # Reshape and apply output projection\n",
    "        x = self.output_proj(x)  # Shape: (batch, seq_length * n_grid, 2)\n",
    "        x = x.view(batch_size, seq_length, n_grid, 2)  # Reshape back\n",
    "        \n",
    "        psi_real_pred, psi_imag_pred = x[..., 0], x[..., 1]\n",
    "        return psi_real_pred, psi_imag_pred\n",
    "\n",
    "# Move model to CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "n_grid = 100  # Example grid size\n",
    "model = QuantumTransformer(n_grid).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
