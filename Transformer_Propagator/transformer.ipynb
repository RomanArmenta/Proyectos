{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumTransformer(nn.Module):\n",
    "    def __init__(self, d_model=128, num_heads=8, num_layers=4, dim_feedforward=256, dropout=0.1, seq_length=100, device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")):\n",
    "        \"\"\"\n",
    "        Transformer model for quantum wavefunction propagation.\n",
    "        - d_model: Dimension of token embeddings.\n",
    "        - num_heads: Number of attention heads.\n",
    "        - num_layers: Number of Transformer layers.\n",
    "        - dim_feedforward: Size of the feedforward network.\n",
    "        - dropout: Dropout rate.\n",
    "        - seq_length: Number of spatial grid points.\n",
    "        \"\"\"\n",
    "        super(QuantumTransformer, self).__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.seq_length = seq_length\n",
    "\n",
    "        # Input embedding (wavefunction + potential energy)\n",
    "        self.embedding = nn.Linear(3, d_model)  # (Re(Ψ), Im(Ψ), V) → d_model\n",
    "        \n",
    "        # Positional encoding (adds spatial dependence)\n",
    "        self.positional_encoding = self.create_positional_encoding(seq_length, d_model).to(device)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=num_heads, dim_feedforward=dim_feedforward, dropout=dropout\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Output layer: Predicts next wavefunction (Re and Im parts)\n",
    "        self.output_layer = nn.Linear(d_model, 2)  # Output (Re(Ψ), Im(Ψ))\n",
    "\n",
    "    def forward(self, psi_real, psi_imag, potential):\n",
    "        \"\"\"\n",
    "        Forward pass of the Transformer.\n",
    "        Input:\n",
    "            - psi_real: Real part of wavefunction (batch, seq_length)\n",
    "            - psi_imag: Imaginary part of wavefunction (batch, seq_length)\n",
    "            - potential: Potential energy (batch, seq_length)\n",
    "        Output:\n",
    "            - Next-step wavefunction (batch, seq_length, 2) → (Re(Ψ), Im(Ψ))\n",
    "        \"\"\"\n",
    "        # Stack inputs to create feature vector at each spatial position\n",
    "        x = torch.stack([psi_real, psi_imag, potential], dim=-1)  # Shape: (batch, seq_length, 3)\n",
    "\n",
    "        # Apply linear embedding\n",
    "        x = self.embedding(x)  # Shape: (batch, seq_length, d_model)\n",
    "\n",
    "        # Add positional encoding\n",
    "        x = x + self.positional_encoding[:x.shape[1], :].to(x.device)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # Output layer: Predict (Re(Ψ), Im(Ψ)) at t + Δt\n",
    "        x = self.output_layer(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class QuantumTransformer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, num_layers, dim_feedforward, dropout, seq_length, n_grid, device):\n",
    "        super(QuantumTransformer, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Linear(3, d_model)  # (Re(Ψ), Im(Ψ), V) → d_model\n",
    "\n",
    "        # Positional Encoding\n",
    "        self.positional_encoding = self.create_positional_encoding(seq_length * n_grid, d_model).to(device)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model, nhead=num_heads, dim_feedforward=dim_feedforward, dropout=dropout\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        # Output layer (maps d_model back to (Re(Ψ), Im(Ψ)))\n",
    "        self.output_layer = nn.Linear(d_model, 2)\n",
    "\n",
    "    def create_positional_encoding(self, full_seq_length, d_model):\n",
    "        \"\"\"\n",
    "        Generate a positional encoding tensor of shape (1, full_seq_length, d_model).\n",
    "        \"\"\"\n",
    "        pos_encoding = torch.zeros(full_seq_length, d_model)\n",
    "        position = torch.arange(0, full_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        pos_encoding[:, 0::2] = torch.sin(position * div_term)\n",
    "        pos_encoding[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        return pos_encoding.unsqueeze(0)  # Shape: (1, full_seq_length, d_model)\n",
    "\n",
    "    def forward(self, psi_real, psi_imag, potential):\n",
    "        # Stack input features along last dimension\n",
    "        x = torch.stack((psi_real, psi_imag, potential), dim=-1)  # Shape: (batch, seq_length, n_grid, 3)\n",
    "        \n",
    "        # Flatten the n_grid dimension into the sequence dimension\n",
    "        batch_size, seq_length, n_grid, _ = x.shape\n",
    "        x = x.view(batch_size, seq_length * n_grid, 3)\n",
    "\n",
    "        # Apply embedding\n",
    "        x = self.embedding(x)  # Shape: (batch, seq_length * n_grid, d_model)\n",
    "        \n",
    "        # Add positional encoding (matching seq_length)\n",
    "        x = x + self.positional_encoding[:, :x.shape[1], :].to(x.device)\n",
    "\n",
    "        # Transformer Encoder\n",
    "        x = self.transformer_encoder(x)\n",
    "\n",
    "        # Apply output layer\n",
    "        x = self.output_layer(x)  # Shape: (batch, seq_length * n_grid, 2)\n",
    "\n",
    "        # Reshape back to (batch, seq_length, n_grid, 2)\n",
    "        x = x.view(batch_size, seq_length, n_grid, 2)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class QuantumWaveDataset(Dataset):\n",
    "    def __init__(self, h5_file):\n",
    "        \"\"\"\n",
    "        Custom PyTorch Dataset for quantum wavefunction propagation.\n",
    "        - h5_file: Path to the .h5 file containing dataset_X and dataset_y.\n",
    "        \"\"\"\n",
    "        with h5py.File(h5_file, \"r\") as f:\n",
    "            self.X = torch.tensor(f[\"dataset_X\"][:], dtype=torch.float32)  # Shape (num_trajectories, sequence_length, n_grid * 3)\n",
    "            self.y = torch.tensor(f[\"dataset_y\"][:], dtype=torch.float32)  # Shape (num_trajectories, sequence_length, n_grid * 2)\n",
    "\n",
    "        # Extract num_trajectories, sequence_length, and n_grid from the shape\n",
    "        self.num_trajectories, self.sequence_length, n_grid_3 = self.X.shape\n",
    "        self.n_grid = n_grid_3 // 3  # Since last dimension is n_grid * 3\n",
    "\n",
    "        # Reshape to (num_trajectories, sequence_length, n_grid, features)\n",
    "        self.X = self.X.view(self.num_trajectories, self.sequence_length, self.n_grid, 3)\n",
    "        self.y = self.y.view(self.num_trajectories, self.sequence_length, self.n_grid, 2)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_trajectories\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]  # Each sample is (sequence_length, n_grid, features)\n",
    "\n",
    "# Load dataset\n",
    "h5_path = \"./DataNew/ngrid64_19932025.h5\"  # Change this to your actual path\n",
    "dataset = QuantumWaveDataset(h5_path)\n",
    "\n",
    "# Create DataLoader for training\n",
    "batch_size = 10\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roman\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = QuantumTransformer(seq_length=dataset.sequence_length, d_model=128, num_heads=8, num_layers=6, dim_feedforward=512, n_grid=64, dropout=0.1, device=device).to(device)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 0.513420\n",
      "Epoch 2/50, Loss: 0.346202\n",
      "Epoch 3/50, Loss: 0.281521\n",
      "Epoch 4/50, Loss: 0.246034\n",
      "Epoch 5/50, Loss: 0.212651\n",
      "Epoch 6/50, Loss: 0.181405\n",
      "Epoch 7/50, Loss: 0.158136\n",
      "Epoch 8/50, Loss: 0.145092\n",
      "Epoch 9/50, Loss: 0.142349\n",
      "Epoch 10/50, Loss: 0.142825\n",
      "Epoch 11/50, Loss: 0.142172\n",
      "Epoch 12/50, Loss: 0.138241\n",
      "Epoch 13/50, Loss: 0.132381\n",
      "Epoch 14/50, Loss: 0.128892\n",
      "Epoch 15/50, Loss: 0.127421\n",
      "Epoch 16/50, Loss: 0.127325\n",
      "Epoch 17/50, Loss: 0.128202\n",
      "Epoch 18/50, Loss: 0.128331\n",
      "Epoch 19/50, Loss: 0.126717\n",
      "Epoch 20/50, Loss: 0.124991\n",
      "Epoch 21/50, Loss: 0.123014\n",
      "Epoch 22/50, Loss: 0.122126\n",
      "Epoch 23/50, Loss: 0.122030\n",
      "Epoch 24/50, Loss: 0.122354\n",
      "Epoch 25/50, Loss: 0.122478\n",
      "Epoch 26/50, Loss: 0.122432\n",
      "Epoch 27/50, Loss: 0.121363\n",
      "Epoch 28/50, Loss: 0.120367\n",
      "Epoch 29/50, Loss: 0.119609\n",
      "Epoch 30/50, Loss: 0.119496\n",
      "Epoch 31/50, Loss: 0.119381\n",
      "Epoch 32/50, Loss: 0.119749\n",
      "Epoch 33/50, Loss: 0.119398\n",
      "Epoch 34/50, Loss: 0.119012\n",
      "Epoch 35/50, Loss: 0.118339\n",
      "Epoch 36/50, Loss: 0.118146\n",
      "Epoch 37/50, Loss: 0.118101\n",
      "Epoch 38/50, Loss: 0.118098\n",
      "Epoch 39/50, Loss: 0.118216\n",
      "Epoch 40/50, Loss: 0.118038\n",
      "Epoch 41/50, Loss: 0.117819\n",
      "Epoch 42/50, Loss: 0.117716\n",
      "Epoch 43/50, Loss: 0.117391\n",
      "Epoch 44/50, Loss: 0.117082\n",
      "Epoch 45/50, Loss: 0.117259\n",
      "Epoch 46/50, Loss: 0.117646\n",
      "Epoch 47/50, Loss: 0.117182\n",
      "Epoch 48/50, Loss: 0.117156\n",
      "Epoch 49/50, Loss: 0.116811\n",
      "Epoch 50/50, Loss: 0.116898\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for X, y in train_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Split inputs into components\n",
    "        psi_real = X[..., 0]  # (batch_size, seq_length, n_grid)\n",
    "        psi_imag = X[..., 1]  # (batch_size, seq_length, n_grid)\n",
    "        potential = X[..., 2] # (batch_size, seq_length, n_grid)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(psi_real, psi_imag, potential)  # Output shape: (batch_size, seq_length, n_grid, 2)\n",
    "\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.6f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
